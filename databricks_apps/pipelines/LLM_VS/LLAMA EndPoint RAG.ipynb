{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b9b62af-c574-453e-b29a-4eb6ae4c4e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch\n",
    "%pip install langchain langchain_community\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f9488fb-a2a7-41c6-8ab6-e0a9de95b9fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text('catalog_name','geekcoders_dev')\n",
    "catalog_name=dbutils.widgets.get('catalog_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32bd2b6e-8fd2-48d8-ada7-17549de92136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vs_endpoint_name='databricks_llm_geekcoders'\n",
    "vs_index_name=f'{catalog_name}.gold.master_dim_patient_info_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f556bbe-b7d9-4d8f-ba80-a1e282a4ac02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc=VectorSearchClient(disable_notice=True)\n",
    "vs_index=vsc.get_index(endpoint_name=vs_endpoint_name,index_name=vs_index_name)\n",
    "vs_index.similarity_search(columns=[\"merged_desc\"],query_text='P_258, Brooke,Davis,132 Main St, City 31 ',num_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ae7794-27bf-4f68-b60b-0d1facd79883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import DatabricksVectorSearch\n",
    "from langchain.embeddings import DatabricksEmbeddings\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.llms import Databricks\n",
    "import json\n",
    "import os\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlflow.deployments import get_deploy_client\n",
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Initialize Vector Search Client\n",
    "vsc = VectorSearchClient()\n",
    "\n",
    "# Define your endpoint and index names\n",
    "vector_search_endpoint_name=vs_endpoint_name\n",
    "vector_index_name=vs_index_name\n",
    "\n",
    "# Define catalog and schema for Unity Catalog\n",
    "UC_CATALOG = f\"{catalog_name}\"\n",
    "UC_SCHEMA = \"gold\"\n",
    "MODEL_NAME = \"geekcoders_chatbot_model\"\n",
    "\n",
    "# Define retriever function\n",
    "def get_retriever():\n",
    "    vs_index = vsc.get_index(\n",
    "        endpoint_name=vector_search_endpoint_name,\n",
    "        index_name=vector_index_name\n",
    "    )\n",
    "    \n",
    "    vectorstore = DatabricksVectorSearch(\n",
    "        vs_index, \n",
    "        text_column=\"merged_desc\"\n",
    "    )\n",
    "    \n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Create the retriever\n",
    "retriever = get_retriever()\n",
    "\n",
    "def transform_input(**request):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts information from text.\"},\n",
    "        {\"role\": \"user\", \"content\": request[\"prompt\"]}\n",
    "    ]\n",
    "    \n",
    "    request[\"messages\"] = messages\n",
    "    del request[\"prompt\"]\n",
    "    return request\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Databricks(\n",
    "    endpoint_name=\"databricks-meta-llama-3-1-405b-instruct\",\n",
    "    transform_input_fn=transform_input\n",
    ")\n",
    "\n",
    "def build_qa_chain():\n",
    "\n",
    "\n",
    "\n",
    "    template = \"\"\"You are an AI assistant that extracts information from text. \n",
    "\n",
    "### Instruction:\n",
    "Extract the relevant details from the provided context. Parse the `merged_desc` field, which contains values joined with the `|` character. If no relevant information is found, respond with: \"Not available.\"\n",
    "\n",
    "return only the final answer with meaningfull sentence\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    prompt = PromptTemplate(input_variables=['context', 'question'], template=template)\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=get_retriever(),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\n",
    "            \"verbose\": True,\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "class ChatBotModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        self.chain = None\n",
    "\n",
    "    def load_context(self, context):\n",
    "        # Initialize the chain when the model is loaded\n",
    "        self.chain = build_qa_chain()\n",
    "        \n",
    "    def predict(self, context, model_input):\n",
    "        # Process the input data consistently\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            question = model_input[\"question\"].iloc[0]\n",
    "        else:\n",
    "            # Handle direct string input or other formats\n",
    "            question = model_input\n",
    "            \n",
    "        # Get the result\n",
    "        result = self.chain({\"query\": question})\n",
    "        \n",
    "        # Consistently extract and format the answer\n",
    "        answer = result[\"result\"]\n",
    "       \n",
    "        return answer\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbcb4efa-cf2b-4d8e-b3cb-7947a721cd52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workspace_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
    "token=dbutils.secrets.get(scope='geekcoders_llm',key='databricks_token')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f77b369d-d11d-466c-af07-5b7e12aa80ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_model_to_uc():\n",
    "    print(\"Saving model to Unity Catalog...\")\n",
    "    \n",
    "    # Define model signature\n",
    "    input_schema = Schema([ColSpec(\"string\", \"question\")])\n",
    "    output_schema = Schema([ColSpec(\"string\", \"answer\")])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "   \n",
    "    \n",
    "    # Set tracking URI to use UC\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    \n",
    "    # Start a new MLflow run\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log model to Unity Catalog\n",
    "        model_info = mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            python_model=ChatBotModel(),\n",
    "            signature=signature,\n",
    "            registered_model_name=f\"{UC_CATALOG}.{UC_SCHEMA}.{MODEL_NAME}\",\n",
    "            pip_requirements=[\"langchain\", \"databricks-vectorsearch\", \"pandas\", \"numpy\", \"mlflow\",\"langchain_community\", \"databricks-sdk\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"Model saved to: {model_info.model_uri}\")\n",
    "        return (model_info.model_uri ,model_info)\n",
    "    \n",
    "def deploy_to_serving_endpoint(model_uri,model_version, endpoint_name=\"geekcoders-chatbot-model\"):\n",
    "    from databricks.sdk import WorkspaceClient\n",
    "    from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedModelInput\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    client = get_deploy_client(\"databricks\")\n",
    "\n",
    "    try:\n",
    "        if(client.get_endpoint(\"geekcoders-chatbot-model\")['state']['ready']=='READY'):\n",
    "             endpoint=client.update_endpoint_config(\"geekcoders-chatbot-model\", config={\n",
    "            \"served_entities\": [\n",
    "                {\n",
    "                    \"entity_name\": f\"{UC_CATALOG}.{UC_SCHEMA}.{MODEL_NAME}\",\n",
    "                    \"entity_version\": model_version,\n",
    "                    \"workload_size\": \"Small\",\n",
    "                    \"workload_type\": \"CPU\",\n",
    "                    \"scale_to_zero_enabled\": True,\n",
    "                    \"environment_vars\": {\"DATABRICKS_HOST\": workspace_url,\n",
    "         \"DATABRICKS_TOKEN\": token}\n",
    "                }\n",
    "                \n",
    "            ], \n",
    "           \n",
    "        }\n",
    "    )\n",
    "    except Exception as e:\n",
    "        endpoint = client.create_endpoint(\n",
    "            name=endpoint_name,\n",
    "            config={\n",
    "                \"served_entities\": [\n",
    "                    {\n",
    "                        \"entity_name\": f\"{UC_CATALOG}.{UC_SCHEMA}.{MODEL_NAME}\",\n",
    "                        \"entity_version\": model_version,\n",
    "                        \"workload_size\": \"Small\",\n",
    "                        \"workload_type\": \"CPU\",\n",
    "                        \"scale_to_zero_enabled\": True,\n",
    "                        \"environment_vars\": {\"DATABRICKS_HOST\": workspace_url,\n",
    "         \"DATABRICKS_TOKEN\": token}\n",
    "                    }\n",
    "                    \n",
    "                ], \n",
    "               \n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(f\"Model deployed to endpoint: {endpoint_name}\")\n",
    "    return endpoint_name\n",
    "\n",
    "#testing  \n",
    "# def answer_question(question):\n",
    "#     qa_chain = build_qa_chain()\n",
    "#     result = qa_chain({\"query\": question})\n",
    "#     return result[\"result\"]\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    \n",
    "    # Save to Unity Catalog\n",
    "    model_uri = save_model_to_uc()\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Deploy to serving endpoint\n",
    "    endpoint_name = deploy_to_serving_endpoint(model_uri[0],model_uri[1].registered_model_version)\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a66da85-0a67-4890-9799-617f46e12501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "status = None\n",
    "client = get_deploy_client(\"databricks\")\n",
    "while True:\n",
    "    state = client.get_endpoint(\"geekcoders-chatbot-model\")['state']['ready']\n",
    "    print(state)\n",
    "    if state == 'READY':\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2556431872152344,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "LLAMA EndPoint RAG",
   "widgets": {
    "catalog_name": {
     "currentValue": "geekcoders_dev",
     "nuid": "7289a6b2-c768-4f71-8c23-adc44725d487",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "geekcoders_dev",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "geekcoders_dev",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
